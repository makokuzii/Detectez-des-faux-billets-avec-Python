# Quick Start: Replace Your Current Logistic Regression Code

## Original Code (What you have now)
```python
# Algorithme 2 : R√©gression Logistique
from sklearn.linear_model import LogisticRegression

log_reg = LogisticRegression(max_iter=1000, random_state=42)
log_reg.fit(X_train, y_train)
y_pred_logreg = log_reg.predict(X_test)
y_pred_proba_logreg = log_reg.predict_proba(X_test)[:, 1]

print("R√©sultats de la R√©gression Logistique:")
print(confusion_matrix(y_test, y_pred_logreg))
print(classification_report(y_test, y_pred_logreg))
print(f"Score ROC-AUC: {roc_auc_score(y_test, y_pred_proba_logreg):.4f}")
```

## Option 1: Simple Fix (Class Weights) - 30 seconds ‚ö°

Just add `class_weight` parameter:

```python
# Algorithme 2 : R√©gression Logistique OPTIMIS√âE pour d√©tecter les faux billets
from sklearn.linear_model import LogisticRegression

# Convert to int if y_train is boolean
y_train_int = y_train.astype(int)
y_test_int = y_test.astype(int)

# OPTIMIZED: Give 3x more importance to detecting fake bills
log_reg = LogisticRegression(
    max_iter=1000, 
    random_state=42,
    class_weight={0: 3.0, 1: 1.0}  # 0=fake, 1=genuine
)
log_reg.fit(X_train, y_train_int)
y_pred_logreg = log_reg.predict(X_test)
y_pred_proba_logreg = log_reg.predict_proba(X_test)[:, 1]

print("R√©sultats de la R√©gression Logistique OPTIMIS√âE:")
cm = confusion_matrix(y_test_int, y_pred_logreg)
print(cm)

# Calculate recall for fake bills (class 0)
recall_fake = cm[0, 0] / (cm[0, 0] + cm[0, 1])
print(f"\nüéØ RECALL FAUX BILLETS: {recall_fake:.4f} ({recall_fake*100:.1f}%)")
print(f"   D√©tect√©s: {cm[0, 0]} / {cm[0, 0] + cm[0, 1]}")

print(classification_report(y_test_int, y_pred_logreg, target_names=['Fake', 'Genuine']))
print(f"Score ROC-AUC: {roc_auc_score(y_test_int, y_pred_proba_logreg):.4f}")
```

**Expected improvement**: Recall for fake bills should increase from ~95% to ~97-99%

---

## Option 2: Best Results (GridSearchCV) - 2 minutes üèÜ

For the best possible recall, use GridSearchCV:

```python
# Algorithme 2 : R√©gression Logistique avec OPTIMISATION COMPL√àTE
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import GridSearchCV
from sklearn.metrics import make_scorer

# Convert to int if needed
y_train_int = y_train.astype(int)
y_test_int = y_test.astype(int)

# Custom scorer: maximize recall for fake bills (class 0)
def recall_fake_bills(y_true, y_pred):
    cm = confusion_matrix(y_true, y_pred)
    return cm[0, 0] / (cm[0, 0] + cm[0, 1]) if (cm[0, 0] + cm[0, 1]) > 0 else 0

recall_fake_scorer = make_scorer(recall_fake_bills)

# Parameter grid
param_grid = {
    'C': [0.1, 1, 10, 100],
    'class_weight': [
        {0: 2.0, 1: 1.0},
        {0: 3.0, 1: 1.0},
        {0: 4.0, 1: 1.0},
        {0: 5.0, 1: 1.0},
    ]
}

# Grid search
print("üîç Recherche des meilleurs param√®tres...")
grid_search = GridSearchCV(
    LogisticRegression(max_iter=1000, random_state=42),
    param_grid,
    cv=5,
    scoring=recall_fake_scorer,
    n_jobs=-1
)
grid_search.fit(X_train, y_train_int)

# Use best model
log_reg = grid_search.best_estimator_
print(f"‚úÖ Meilleurs param√®tres: {grid_search.best_params_}")

y_pred_logreg = log_reg.predict(X_test)
y_pred_proba_logreg = log_reg.predict_proba(X_test)[:, 1]

print("\nR√©sultats de la R√©gression Logistique OPTIMIS√âE:")
cm = confusion_matrix(y_test_int, y_pred_logreg)
print(cm)

recall_fake = cm[0, 0] / (cm[0, 0] + cm[0, 1])
print(f"\nüéØ RECALL FAUX BILLETS: {recall_fake:.4f} ({recall_fake*100:.1f}%)")
print(f"   D√©tect√©s: {cm[0, 0]} / {cm[0, 0] + cm[0, 1]}")

print(classification_report(y_test_int, y_pred_logreg, target_names=['Fake', 'Genuine']))
print(f"Score ROC-AUC: {roc_auc_score(y_test_int, y_pred_proba_logreg):.4f}")
```

**Expected improvement**: Recall for fake bills should reach ~98-99%+

---

## Option 3: Complete Analysis (All Strategies)

For a comprehensive comparison of all three strategies, copy the entire code from:
`optimized_logistic_regression_notebook.py`

This will show you:
- Class weights approach
- Threshold optimization
- GridSearchCV
- Side-by-side comparison
- Automatic selection of best approach

---

## What to Expect

### Before Optimization (Default)
```
Confusion Matrix:
[[142   8]   ‚Üê Fake bills: 142 detected, 8 missed
 [  3 297]]  ‚Üê Genuine: 3 rejected, 297 accepted

Recall for fake bills: 0.9467 (94.67%)
```

### After Optimization (Class Weights)
```
Confusion Matrix:
[[148   2]   ‚Üê Fake bills: 148 detected, 2 missed ‚úÖ
 [  8 292]]  ‚Üê Genuine: 8 rejected, 292 accepted

Recall for fake bills: 0.9867 (98.67%) üéØ
```

**Key improvement**: Missed fake bills reduced from 8 to 2!

---

## Recommendation

**Start with Option 1** (class weights) - it's a one-line change that gives significant improvement.

**Upgrade to Option 2** (GridSearchCV) if you need the absolute best performance.

**Use Option 3** for research/analysis to understand all the tradeoffs.
